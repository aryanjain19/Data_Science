{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "c0f70214c0dd213f07f54ee5d6e0ea644bdbba35113c9bfe8aaa0d1db03ad5dd"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"train.csv\")\n",
    "df=data.drop(columns=[\"id\"])\n",
    "\n",
    "# sample = np.random.choice(data.index, size=20)\n",
    "# df = df.iloc[sample]\n",
    "\n",
    "y=df['target']\n",
    "y=y.values.reshape(200000,1)\n",
    "# x=sample_df.drop('target', axis=1)\n",
    "for j in range(200000):\n",
    "    i=y[j]\n",
    "    if i=='Class_1':\n",
    "        y[j]=0\n",
    "    if i=='Class_2':\n",
    "        y[j]=1\n",
    "    if i=='Class_3':\n",
    "        y[j]=2\n",
    "    if i=='Class_4':\n",
    "        y[j]=3\n",
    "    if i=='Class_5':\n",
    "        y[j]=4\n",
    "    if i=='Class_6':\n",
    "        y[j]=5\n",
    "    if i=='Class_7':\n",
    "        y[j]=6\n",
    "    if i=='Class_8':\n",
    "        y[j]=7\n",
    "    if i=='Class_9':\n",
    "        y[j]=8\n",
    "\n",
    "\n",
    "#0,1,4,6,7,26,30,40,44,54,60\n",
    "# 15,16,24,36,46,47,55,73\n",
    "df=df.drop(columns=[\"feature_0\",\"feature_1\",\"feature_4\",\"feature_6\",\"feature_7\",\"feature_26\",\"feature_30\",\"feature_40\",\"feature_44\",\"feature_54\",\"feature_60\",\"feature_15\",\"feature_16\",\"feature_24\",\"feature_36\",\"feature_46\",\"feature_47\",\"feature_55\",\"feature_73\"])\n",
    "df=df.astype(float)\n",
    "\n",
    "df=torch.tensor(df.values)\n",
    "q1,q2=torch.max(df,dim=0)\n",
    "df=torch.divide(df,q1)\n",
    "# df[:,:75]=df[:,:75].float()\n",
    "# df[:,75]=df[:,75]*8\n",
    "# df[:,75]=df[:,75].long()\n",
    "df[:,:56]=df[:,:56].float()\n",
    "df[:,56]=df[:,56]*8\n",
    "df[:,56]=df[:,56].long()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(df,batch_size=64,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf=pd.read_csv(\"train.csv\")\n",
    "tdf=tdf.drop(columns=[\"id\"])\n",
    "\n",
    "# taking a 1000 sample to test training \n",
    "sample = np.random.choice(data.index, size=2000)\n",
    "sample_tdf = tdf.iloc[sample]\n",
    "\n",
    "yt=sample_tdf['target']\n",
    "yt=yt.values.reshape(2000,1)\n",
    "# x=sample_df.drop('target', axis=1)\n",
    "for j in range(2000):\n",
    "    i=yt[j]\n",
    "    if i=='Class_1':\n",
    "        yt[j]=0\n",
    "    if i=='Class_2':\n",
    "        yt[j]=1\n",
    "    if i=='Class_3':\n",
    "        yt[j]=2\n",
    "    if i=='Class_4':\n",
    "        yt[j]=3\n",
    "    if i=='Class_5':\n",
    "        yt[j]=4\n",
    "    if i=='Class_6':\n",
    "        yt[j]=5\n",
    "    if i=='Class_7':\n",
    "        yt[j]=6\n",
    "    if i=='Class_8':\n",
    "        yt[j]=7\n",
    "    if i=='Class_9':\n",
    "        yt[j]=8\n",
    "\n",
    "#sample_tdf = sample_tdf.apply(pd.to_numeric,downcast='float')\n",
    "sample_tdf=sample_tdf.astype(int)\n",
    "sample_tdf=torch.tensor(sample_tdf.values)\n",
    "q1,q2=torch.max(sample_tdf,dim=0)\n",
    "sample_tdf=torch.divide(sample_tdf,q1)\n",
    "sample_tdf[:,:75]=sample_tdf[:,:75].float()\n",
    "sample_tdf[:,75]=sample_tdf[:,75]*8\n",
    "sample_tdf[:,75]=sample_tdf[:,75].long()\n",
    "tdataloader = torch.utils.data.DataLoader(sample_tdf,batch_size=64,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1=nn.Linear(56,40)\n",
    "        self.fc2=nn.Linear(40,30)\n",
    "        self.fc3=nn.Linear(30,20)\n",
    "        self.fc4=nn.Linear(20,9)\n",
    "        #self.dropout=nn.Dropout(p=0.2)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x=x.view(x.shape[0],-1)\n",
    "        # x=self.dropout(F.relu(self.fc1(x)))\n",
    "        # x=self.dropout(F.relu(self.fc2(x)))\n",
    "        # x=self.dropout(F.relu(self.fc3(x)))\n",
    "        # x=F.log_softmax(self.fc4(x),dim=1)\n",
    "        x=F.relu(self.fc1(x))\n",
    "        x=F.relu(self.fc2(x))\n",
    "        x=F.relu(self.fc3(x))\n",
    "        x=F.log_softmax(self.fc4(x),dim=1)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch  1   Train Accuracy = 34.375   Train Loss = 1.8399406179046631\n",
      "epoch  2   Train Accuracy = 43.75   Train Loss = 1.8077767453002929\n",
      "epoch  3   Train Accuracy = 29.6875   Train Loss = 1.8017017454528808\n",
      "epoch  4   Train Accuracy = 34.375   Train Loss = 1.79614563331604\n",
      "epoch  5   Train Accuracy = 34.375   Train Loss = 1.7923634576034546\n",
      "epoch  6   Train Accuracy = 28.125   Train Loss = 1.7903159042358399\n",
      "epoch  7   Train Accuracy = 35.9375   Train Loss = 1.7886287504959106\n",
      "epoch  8   Train Accuracy = 31.25   Train Loss = 1.787098802947998\n",
      "epoch  9   Train Accuracy = 42.1875   Train Loss = 1.7858175561141967\n",
      "epoch  10   Train Accuracy = 39.0625   Train Loss = 1.7844912972640992\n",
      "epoch  11   Train Accuracy = 32.8125   Train Loss = 1.7837494951629638\n",
      "epoch  12   Train Accuracy = 42.1875   Train Loss = 1.7830065526199341\n",
      "epoch  13   Train Accuracy = 35.9375   Train Loss = 1.7821045766830443\n",
      "epoch  14   Train Accuracy = 29.6875   Train Loss = 1.7809850686264037\n",
      "epoch  15   Train Accuracy = 37.5   Train Loss = 1.7812761683654785\n",
      "epoch  16   Train Accuracy = 37.5   Train Loss = 1.780285262260437\n",
      "epoch  17   Train Accuracy = 34.375   Train Loss = 1.7794342800140381\n",
      "epoch  18   Train Accuracy = 34.375   Train Loss = 1.7792739649963378\n",
      "epoch  19   Train Accuracy = 42.1875   Train Loss = 1.7794331677627564\n",
      "epoch  20   Train Accuracy = 35.9375   Train Loss = 1.7782515920257569\n",
      "epoch  21   Train Accuracy = 42.1875   Train Loss = 1.7780907794952392\n",
      "epoch  22   Train Accuracy = 32.8125   Train Loss = 1.7776359027099609\n",
      "epoch  23   Train Accuracy = 34.375   Train Loss = 1.777435897102356\n",
      "epoch  24   Train Accuracy = 25.0   Train Loss = 1.7767756610107421\n",
      "epoch  25   Train Accuracy = 42.1875   Train Loss = 1.7758728358840943\n",
      "epoch  26   Train Accuracy = 35.9375   Train Loss = 1.7758295415496825\n",
      "epoch  27   Train Accuracy = 34.375   Train Loss = 1.7754822166442872\n",
      "epoch  28   Train Accuracy = 45.3125   Train Loss = 1.7749151672744752\n",
      "epoch  29   Train Accuracy = 51.5625   Train Loss = 1.7748532244491577\n",
      "epoch  30   Train Accuracy = 35.9375   Train Loss = 1.774341252708435\n"
     ]
    }
   ],
   "source": [
    "model=Network()\n",
    "criterion=nn.NLLLoss()\n",
    "optimizer=optim.SGD(model.parameters(),lr=0.6)\n",
    "epoch=30\n",
    "\n",
    "for e in range(epoch):\n",
    "    run_loss=0\n",
    "    for data in dataloader:\n",
    "        x=data[:,:56].float()\n",
    "        y=data[:,56].long()\n",
    "        #print(y)\n",
    "        optimizer.zero_grad()\n",
    "        out=model(x)\n",
    "        #print(torch.exp(out))\n",
    "        loss=criterion(out,y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        run_loss+=loss.item()\n",
    "    else :\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            ps=model(x)\n",
    "            model.train()\n",
    "        p=torch.exp(ps)\n",
    "        top_val,top_indx=p.topk(1,dim=1)\n",
    "        #print(top_indx,y)\n",
    "        match=top_indx==y.view(*top_indx.shape)\n",
    "        acc=torch.mean(match.type(torch.FloatTensor))\n",
    "        print(\"epoch \",e+1,\"  Train Accuracy =\",acc.item()*100,\"  Train Loss =\",run_loss/len(dataloader))\n",
    "\n",
    "# model=Network()\n",
    "# criterion=nn.NLLLoss()\n",
    "# optimizer=optim.SGD(model.parameters(),lr=0.6)\n",
    "# epoch=20\n",
    "\n",
    "# for e in range(epoch):\n",
    "#     run_loss=0\n",
    "#     for data in dataloader:\n",
    "#         x=data[:,:75].float()\n",
    "#         y=data[:,75].long()\n",
    "#         #print(y)\n",
    "#         optimizer.zero_grad()\n",
    "#         out=model(x)\n",
    "#         #print(torch.exp(out))\n",
    "#         loss=criterion(out,y)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         run_loss+=loss.item()\n",
    "#     else :\n",
    "#         with torch.no_grad():\n",
    "#             model.eval()\n",
    "#             ps=model(x)\n",
    "#             model.train()\n",
    "#         p=torch.exp(ps)\n",
    "#         top_val,top_indx=p.topk(1,dim=1)\n",
    "#         #print(top_indx,y)\n",
    "#         match=top_indx==y.view(*top_indx.shape)\n",
    "#         acc=torch.mean(match.type(torch.FloatTensor))\n",
    "\n",
    "#         run_loss1=0\n",
    "#         for tdata in tdataloader:\n",
    "#                 xt=tdata[:,:75]\n",
    "#                 yt=tdata[:,75]\n",
    "#                 yt = yt.type(torch.LongTensor)\n",
    "#                 with torch.no_grad():\n",
    "#                     model.eval()\n",
    "#                     ps=model(xt)\n",
    "#                     model.train()\n",
    "#                 p=torch.exp(ps)\n",
    "#                 max_val,max_indx=p.topk(1,dim=1)\n",
    "#                 match=max_indx==yt.view(*max_indx.shape)\n",
    "#                 acc1=torch.mean(match.type(torch.FloatTensor))\n",
    "#                 run_loss1+=acc1.item()\n",
    "#         print(\"epoch \",e+1,\"  Train Accuracy =\",acc.item()*100,\" Test accuracy =\",run_loss1*100/len(tdataloader),\"  Train Loss =\",run_loss/len(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove=[0,1,4,6,7,26,30,40,44,54,60,15,16,24,36,46,47,55,73]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(56):\n",
    "#     if i>=0:\n",
    "#         class Network(nn.Module):\n",
    "#             def __init__(self):\n",
    "#                 super().__init__()\n",
    "#                 self.fc1=nn.Linear(55,40)\n",
    "#                 self.fc2=nn.Linear(40,25)\n",
    "#                 self.fc3=nn.Linear(25,9)\n",
    "#                 #self.dropout=nn.Dropout(p=0)\n",
    "            \n",
    "#             def forward(self,x):\n",
    "#                 x=x.view(x.shape[0],-1)\n",
    "#                 # x=self.dropout(F.relu(self.fc1(x)))\n",
    "#                 # x=self.dropout(F.relu(self.fc2(x)))\n",
    "#                 # x=self.dropout(F.relu(self.fc3(x)))\n",
    "#                 # x=self.dropout(F.relu(self.fc4(x)))\n",
    "#                 # x=F.log_softmax(self.fc5(x),dim=1)\n",
    "#                 x=F.relu(self.fc1(x))\n",
    "#                 x=F.relu(self.fc2(x))\n",
    "#                 x=F.log_softmax(self.fc3(x),dim=1)\n",
    "#                 return x\n",
    "\n",
    "\n",
    "#         model=Network()\n",
    "#         criterion=nn.NLLLoss()\n",
    "#         optimizer=optim.SGD(model.parameters(),lr=0.6)\n",
    "#         epoch=1\n",
    "\n",
    "\n",
    "#         for e in range(epoch):\n",
    "#             run_loss=0\n",
    "#             for data in dataloader:\n",
    "#                 x=data[:,:56]\n",
    "#                 x = torch.cat((x[:,:i],x[:,i+1:]),dim=1)\n",
    "#                 x=x.float()\n",
    "#                 y=data[:,56].long()\n",
    "#                 #print(y)\n",
    "#                 optimizer.zero_grad()\n",
    "#                 out=model(x)\n",
    "#                 #print(torch.exp(out))\n",
    "#                 loss=criterion(out,y)\n",
    "#                 loss.backward()\n",
    "#                 optimizer.step()\n",
    "#                 run_loss+=loss.item()\n",
    "#             else :\n",
    "#                 with torch.no_grad():\n",
    "#                     model.eval()\n",
    "#                     ps=model(x)\n",
    "#                     model.train()\n",
    "#                 p=torch.exp(ps)\n",
    "#                 top_val,top_indx=p.topk(1,dim=1)\n",
    "#                 #print(top_indx,y)\n",
    "#                 match=top_indx==y.view(*top_indx.shape)\n",
    "#                 acc=torch.mean(match.type(torch.FloatTensor))\n",
    "#                 print(\"col \",i,\"  Train Accuracy =\",acc.item()*100,\"  Train Loss =\",run_loss/len(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = {'input_size': 56,\n",
    "              'output_size': 9,\n",
    "              'hidden_layers': [40,30,20],\n",
    "              'state_dict': model.state_dict()}\n",
    "\n",
    "torch.save(checkpoint, 'checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Network(\n  (fc1): Linear(in_features=56, out_features=40, bias=True)\n  (fc2): Linear(in_features=40, out_features=30, bias=True)\n  (fc3): Linear(in_features=30, out_features=20, bias=True)\n  (fc4): Linear(in_features=20, out_features=9, bias=True)\n  (dropout): Dropout(p=0.2, inplace=False)\n)\n"
     ]
    }
   ],
   "source": [
    "def load_checkpoint(filepath):\n",
    "    checkpoint = torch.load(filepath)\n",
    "    model = Network()\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    return model\n",
    "\n",
    "model = load_checkpoint('checkpoint.pth')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.read_csv(\"test.csv\")\n",
    "dfy=df1[\"id\"]\n",
    "dfx=df1.drop(columns=[\"id\",\"feature_0\",\"feature_1\",\"feature_4\",\"feature_6\",\"feature_7\",\"feature_26\",\"feature_30\",\"feature_40\",\"feature_44\",\"feature_54\",\"feature_60\",\"feature_15\",\"feature_16\",\"feature_24\",\"feature_36\",\"feature_46\",\"feature_47\",\"feature_55\",\"feature_73\"])\n",
    "\n",
    "dfx = dfx.astype(float)\n",
    "dfx=torch.tensor(dfx.values)\n",
    "\n",
    "dfy=dfy.values.reshape(len(df1),1)\n",
    "dfy=torch.from_numpy(dfy)\n",
    "\n",
    "q1,q2=torch.max(dfx,dim=0)\n",
    "dfx=torch.divide(dfx,q1)\n",
    "df1=torch.cat((dfy,dfx),dim=1)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(df1,batch_size=100000,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "pridict=pd.DataFrame()\n",
    "ids=pd.DataFrame()\n",
    "for data in testloader:\n",
    "    id=data[:,0]\n",
    "    x=data[:,1:57]\n",
    "    with torch.no_grad():\n",
    "        ps=model(x.float())\n",
    "    p=torch.exp(ps)\n",
    "    #max_val,max_indx=p.topk(1,dim=1)\n",
    "    \n",
    "    #max_indx=max_indx.squeeze().tolist()\n",
    "    #max_indx=max_indx[:]\n",
    "    #id=id.squeeze().tolist()\n",
    "    #id=id[:]\n",
    "    p=p.float()\n",
    "    id=id.long()\n",
    "    df_p=pd.DataFrame(p,columns=[\"Class_1\",\"Class_2\",\"Class_3\",\"Class_4\",\"Class_5\",\"Class_6\",\"Class_7\",\"Class_8\",\"Class_9\"])\n",
    "    pridict=pridict.append(df_p)\n",
    "    df_id=pd.DataFrame(id,columns=[\"id\"])\n",
    "    ids=ids.append(df_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pridict=pridict.astype(float)\n",
    "ids=ids.astype(int)\n",
    "df=pd.concat([ids,pridict],axis=1)\n",
    "df.to_csv('final_pridictions_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}