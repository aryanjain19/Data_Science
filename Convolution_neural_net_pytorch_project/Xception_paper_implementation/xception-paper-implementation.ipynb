{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nimport torchvision\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport time","metadata":{"execution":{"iopub.status.busy":"2021-08-02T12:08:51.836749Z","iopub.execute_input":"2021-08-02T12:08:51.837236Z","iopub.status.idle":"2021-08-02T12:08:53.148703Z","shell.execute_reply.started":"2021-08-02T12:08:51.837142Z","shell.execute_reply":"2021-08-02T12:08:53.147823Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"train_on_gpu = torch.cuda.is_available()\n\nif not train_on_gpu:\n    print('CUDA is not available.  Training on CPU ...')\nelse:\n    print('CUDA is available!  Training on GPU ...')","metadata":{"execution":{"iopub.status.busy":"2021-08-02T12:08:54.392442Z","iopub.execute_input":"2021-08-02T12:08:54.392822Z","iopub.status.idle":"2021-08-02T12:08:54.463663Z","shell.execute_reply.started":"2021-08-02T12:08:54.392771Z","shell.execute_reply":"2021-08-02T12:08:54.462413Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"CUDA is available!  Training on GPU ...\n","output_type":"stream"}]},{"cell_type":"code","source":"from torchvision import datasets\nimport torchvision.transforms as transforms\nfrom torch.utils.data.sampler import SubsetRandomSampler\n\n# number of subprocesses to use for data loading\nnum_workers = 0\n# how many samples per batch to load\nbatch_size = 24\n# percentage of training set to use as validation\nvalid_size = 0.2\n\n# convert data to a normalized torch.FloatTensor\ntransform = transforms.Compose([\n    transforms.Resize([299, 299]),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n    ])\n\n# choose the training and test datasets\ntrain_data = datasets.CIFAR10('data', train=True,\n                              download=True, transform=transform)\ntest_data = datasets.CIFAR10('data', train=False,\n                             download=True, transform=transform)\n\n# obtain training indices that will be used for validation\nnum_train = len(train_data)\nindices = list(range(num_train))\nnp.random.shuffle(indices)\nsplit = int(np.floor(valid_size * num_train))\ntrain_idx, valid_idx = indices[split:], indices[:split]\n\n# define samplers for obtaining training and validation batches\ntrain_sampler = SubsetRandomSampler(train_idx)\nvalid_sampler = SubsetRandomSampler(valid_idx)\n\n# prepare data loaders (combine dataset and sampler)\ntrain_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n    sampler=train_sampler, num_workers=num_workers)\nvalid_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, \n    sampler=valid_sampler, num_workers=num_workers)\ntest_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n    num_workers=num_workers)\n\n# specify the image classes\nclasses = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n           'dog', 'frog', 'horse', 'ship', 'truck']","metadata":{"execution":{"iopub.status.busy":"2021-08-02T12:08:59.588231Z","iopub.execute_input":"2021-08-02T12:08:59.588546Z","iopub.status.idle":"2021-08-02T12:09:06.605701Z","shell.execute_reply.started":"2021-08-02T12:08:59.588518Z","shell.execute_reply":"2021-08-02T12:09:06.604800Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1212905b6c44bdbb6426f2bcd725f47"}},"metadata":{}},{"name":"stdout","text":"Extracting data/cifar-10-python.tar.gz to data\nFiles already downloaded and verified\n","output_type":"stream"}]},{"cell_type":"code","source":"class EntryFlowLoop(nn.Module):\n    def __init__(self,in_channels,out_channels,relu_start):\n        super(EntryFlowLoop,self).__init__()\n        self.relu_start=relu_start\n        \n        self.conv=nn.Conv2d(in_channels,out_channels,1,stride=2)\n        self.bnc=nn.BatchNorm2d(out_channels)\n        \n        self.sc1a=nn.Conv2d(in_channels,in_channels,3,groups=in_channels,padding=1,bias=False)\n        self.sc1b=nn.Conv2d(in_channels,out_channels,1,bias=False)\n        self.bn1=nn.BatchNorm2d(out_channels)\n        \n        self.sc2a=nn.Conv2d(out_channels,out_channels,3,groups=out_channels,padding=1,bias=False)\n        self.sc2b=nn.Conv2d(out_channels,out_channels,1,bias=False)\n        self.bn2=nn.BatchNorm2d(out_channels)\n        \n        self.maxpool=nn.MaxPool2d(kernel_size=(3,3),stride=2,padding=1)\n        self.relu=nn.ReLU()\n    \n    def forward(self,x):\n                \n        output=self.conv(x)\n        output=self.bnc(output)\n        \n        if self.relu_start==True:\n            x=self.relu(x)\n        \n        x=self.sc1b(self.sc1a(x))\n        x=self.bn1(x)\n        x=self.relu(x)\n        \n        x=self.sc2b(self.sc2a(x))\n        x=self.bn2(x)\n        x=self.maxpool(x)\n        \n        x+=output\n        \n        return x\n\n\nclass EntryFlowFinal(nn.Module):\n    def __init__(self):\n        super(EntryFlowFinal,self).__init__()\n        \n        self.c1=nn.Conv2d(3,32,3,stride=2)\n        self.bn1=nn.BatchNorm2d(32)\n\n        self.c2=nn.Conv2d(32,64,3)\n        self.bn2=nn.BatchNorm2d(64)\n        \n        self.loop1=EntryFlowLoop(64,128,False)\n        self.loop2=EntryFlowLoop(128,256,True)\n        self.loop3=EntryFlowLoop(256,728,True)\n        \n        self.relu=nn.ReLU()\n    \n    def forward(self,x):\n        x=self.c1(x)\n        x=self.bn1(x)\n        x=self.relu(x)\n        \n        x=self.c2(x)\n        x=self.bn2(x)\n        x=self.relu(x)\n        \n        x=self.loop1(x)\n        x=self.loop2(x)\n        x=self.loop3(x)\n        \n        return x","metadata":{"execution":{"iopub.status.busy":"2021-08-02T12:09:12.468607Z","iopub.execute_input":"2021-08-02T12:09:12.468944Z","iopub.status.idle":"2021-08-02T12:09:12.485862Z","shell.execute_reply.started":"2021-08-02T12:09:12.468913Z","shell.execute_reply":"2021-08-02T12:09:12.485059Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"class MiddleFlow(nn.Module):\n    def __init__(self,channels=728):\n        super(MiddleFlow,self).__init__()\n        \n        self.sc1a=nn.Conv2d(728,728,3,groups=728,padding=1,bias=False)\n        self.sc1b=nn.Conv2d(728,728,1,bias=False)\n        \n        self.sc2a=nn.Conv2d(728,728,3,groups=728,padding=1,bias=False)\n        self.sc2b=nn.Conv2d(728,728,1,bias=False)\n        \n        self.sc3a=nn.Conv2d(728,728,3,groups=728,padding=1,bias=False)\n        self.sc3b=nn.Conv2d(728,728,1,bias=False)\n        \n        \n        self.bn1=nn.BatchNorm2d(728)\n        self.bn2=nn.BatchNorm2d(728)\n        self.bn3=nn.BatchNorm2d(728)\n        self.relu=nn.ReLU()\n        \n    def forward(self,x):\n        output=x\n        \n        x=self.sc1b(self.sc1a(self.relu(x)))\n        x=self.bn1(x)\n        x=self.sc2b(self.sc2a(self.relu(x)))\n        x=self.bn2(x)\n        x=self.sc3b(self.sc3a(self.relu(x)))\n        x=self.bn3(x)\n        \n        x=x+output\n        \n        return x\n\n    \nclass MiddleFlowFinal(nn.Module):\n    def __init__(self):\n        super(MiddleFlowFinal,self).__init__()\n        self.cycle1=MiddleFlow()\n        self.cycle2=MiddleFlow()\n        self.cycle3=MiddleFlow()\n        self.cycle4=MiddleFlow()\n        self.cycle5=MiddleFlow()\n        self.cycle6=MiddleFlow()\n        self.cycle7=MiddleFlow()\n        self.cycle8=MiddleFlow()\n    \n    \n    \n    def forward(self,x):\n#         for i in range(8):\n#             x=self.cycle(x)\n        x=self.cycle1(x)\n        x=self.cycle2(x)\n        x=self.cycle3(x)\n        x=self.cycle4(x)\n        x=self.cycle5(x)\n        x=self.cycle6(x)\n        x=self.cycle7(x)\n        x=self.cycle8(x)\n        \n        return x","metadata":{"execution":{"iopub.status.busy":"2021-08-02T12:09:14.928507Z","iopub.execute_input":"2021-08-02T12:09:14.928840Z","iopub.status.idle":"2021-08-02T12:09:14.942516Z","shell.execute_reply.started":"2021-08-02T12:09:14.928788Z","shell.execute_reply":"2021-08-02T12:09:14.941483Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class ExitFlowFinal(nn.Module):\n    def __init__(self):\n        super(ExitFlowFinal,self).__init__()\n        \n        self.c1=nn.Conv2d(728,1024,1,stride=2)\n        self.bnc=nn.BatchNorm2d(1024)\n        \n        self.sc1a=nn.Conv2d(728,728,3,groups=728,padding=1,bias=False)\n        self.sc1b=nn.Conv2d(728,728,1,bias=False)\n        self.bn1=nn.BatchNorm2d(728)\n        \n        self.sc2a=nn.Conv2d(728,728,3,groups=728,padding=1,bias=False)\n        self.sc2b=nn.Conv2d(728,1024,1,bias=False)\n        self.bn2=nn.BatchNorm2d(1024)\n\n        self.sc3a=nn.Conv2d(1024,1024,3,groups=1024,padding=1,bias=False)\n        self.sc3b=nn.Conv2d(1024,1536,1,bias=False)\n        self.bn3=nn.BatchNorm2d(1536)\n\n        self.sc4a=nn.Conv2d(1536,1536,3,groups=1536,padding=1,bias=False)\n        self.sc4b=nn.Conv2d(1536,2048,1,bias=False)\n        self.bn4=nn.BatchNorm2d(2048)\n        \n        self.maxpool=nn.MaxPool2d(kernel_size=(3,3),stride=2,padding=1)\n        self.relu=nn.ReLU()\n        self.avgpool=nn.AvgPool2d(kernel_size=(10,10))\n        \n    def forward(self,x):\n        output=self.c1(x)\n        output=self.bnc(output)\n        \n        x=self.relu(x)\n        x=self.sc1b(self.sc1a(x))\n        x=self.bn1(x)\n        \n        x=self.relu(x)\n        x=self.sc2b(self.sc2a(x))\n        x=self.bn2(x)\n        \n        x=self.maxpool(x)\n        x+=output\n        \n        x=self.sc3b(self.sc3a(x))\n        x=self.bn3(x)        \n        x=self.relu(x)\n        \n        x=self.sc4b(self.sc4a(x))\n        x=self.bn4(x)        \n        x=self.relu(x)\n        \n        x=self.avgpool(x)\n        \n        return x   ","metadata":{"execution":{"iopub.status.busy":"2021-08-02T12:09:16.549118Z","iopub.execute_input":"2021-08-02T12:09:16.549432Z","iopub.status.idle":"2021-08-02T12:09:16.562825Z","shell.execute_reply.started":"2021-08-02T12:09:16.549403Z","shell.execute_reply":"2021-08-02T12:09:16.561754Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class Xception_implementation(nn.Module):\n    def __init__(self):\n        super(Xception_implementation,self).__init__()       \n        \n        self.entry=EntryFlowFinal()\n        self.middle=MiddleFlowFinal()\n        self.exit=ExitFlowFinal()\n        \n        self.fc1=nn.Linear(2048,512)\n        self.ol=nn.Linear(512,275)\n        \n        self.relu=nn.ReLU()\n\n    def forward(self,x):\n        \n        x=self.entry(x)\n        x=self.middle(x)\n        x=self.exit(x)\n        \n        x = x.view(x.size(0), -1) \n        x=self.relu(self.fc1(x))\n        x=self.relu(self.ol(x))\n        return x\n\n\nmodel = Xception_implementation()\n#print(model)\n\n# move tensors to GPU if CUDA is available\nif train_on_gpu:\n    model.cuda()\n! pip install torch-summary\nfrom torchsummary import summary\nsummary(model,(3,299,299))","metadata":{"execution":{"iopub.status.busy":"2021-08-02T12:09:20.332379Z","iopub.execute_input":"2021-08-02T12:09:20.332688Z","iopub.status.idle":"2021-08-02T12:09:32.799959Z","shell.execute_reply.started":"2021-08-02T12:09:20.332659Z","shell.execute_reply":"2021-08-02T12:09:32.799077Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Collecting torch-summary\n  Downloading torch_summary-1.4.5-py3-none-any.whl (16 kB)\nInstalling collected packages: torch-summary\nSuccessfully installed torch-summary-1.4.5\n==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\n├─EntryFlowFinal: 1-1                    [-1, 728, 19, 19]         --\n|    └─Conv2d: 2-1                       [-1, 32, 149, 149]        896\n|    └─BatchNorm2d: 2-2                  [-1, 32, 149, 149]        64\n|    └─ReLU: 2-3                         [-1, 32, 149, 149]        --\n|    └─Conv2d: 2-4                       [-1, 64, 147, 147]        18,496\n|    └─BatchNorm2d: 2-5                  [-1, 64, 147, 147]        128\n|    └─ReLU: 2-6                         [-1, 64, 147, 147]        --\n|    └─EntryFlowLoop: 2-7                [-1, 128, 74, 74]         --\n|    |    └─Conv2d: 3-1                  [-1, 128, 74, 74]         8,320\n|    |    └─BatchNorm2d: 3-2             [-1, 128, 74, 74]         256\n|    |    └─Conv2d: 3-3                  [-1, 64, 147, 147]        576\n|    |    └─Conv2d: 3-4                  [-1, 128, 147, 147]       8,192\n|    |    └─BatchNorm2d: 3-5             [-1, 128, 147, 147]       256\n|    |    └─ReLU: 3-6                    [-1, 128, 147, 147]       --\n|    |    └─Conv2d: 3-7                  [-1, 128, 147, 147]       1,152\n|    |    └─Conv2d: 3-8                  [-1, 128, 147, 147]       16,384\n|    |    └─BatchNorm2d: 3-9             [-1, 128, 147, 147]       256\n|    |    └─MaxPool2d: 3-10              [-1, 128, 74, 74]         --\n|    └─EntryFlowLoop: 2-8                [-1, 256, 37, 37]         --\n|    |    └─Conv2d: 3-11                 [-1, 256, 37, 37]         33,024\n|    |    └─BatchNorm2d: 3-12            [-1, 256, 37, 37]         512\n|    |    └─ReLU: 3-13                   [-1, 128, 74, 74]         --\n|    |    └─Conv2d: 3-14                 [-1, 128, 74, 74]         1,152\n|    |    └─Conv2d: 3-15                 [-1, 256, 74, 74]         32,768\n|    |    └─BatchNorm2d: 3-16            [-1, 256, 74, 74]         512\n|    |    └─ReLU: 3-17                   [-1, 256, 74, 74]         --\n|    |    └─Conv2d: 3-18                 [-1, 256, 74, 74]         2,304\n|    |    └─Conv2d: 3-19                 [-1, 256, 74, 74]         65,536\n|    |    └─BatchNorm2d: 3-20            [-1, 256, 74, 74]         512\n|    |    └─MaxPool2d: 3-21              [-1, 256, 37, 37]         --\n|    └─EntryFlowLoop: 2-9                [-1, 728, 19, 19]         --\n|    |    └─Conv2d: 3-22                 [-1, 728, 19, 19]         187,096\n|    |    └─BatchNorm2d: 3-23            [-1, 728, 19, 19]         1,456\n|    |    └─ReLU: 3-24                   [-1, 256, 37, 37]         --\n|    |    └─Conv2d: 3-25                 [-1, 256, 37, 37]         2,304\n|    |    └─Conv2d: 3-26                 [-1, 728, 37, 37]         186,368\n|    |    └─BatchNorm2d: 3-27            [-1, 728, 37, 37]         1,456\n|    |    └─ReLU: 3-28                   [-1, 728, 37, 37]         --\n|    |    └─Conv2d: 3-29                 [-1, 728, 37, 37]         6,552\n|    |    └─Conv2d: 3-30                 [-1, 728, 37, 37]         529,984\n|    |    └─BatchNorm2d: 3-31            [-1, 728, 37, 37]         1,456\n|    |    └─MaxPool2d: 3-32              [-1, 728, 19, 19]         --\n├─MiddleFlowFinal: 1-2                   [-1, 728, 19, 19]         --\n|    └─MiddleFlow: 2-10                  [-1, 728, 19, 19]         --\n|    |    └─ReLU: 3-33                   [-1, 728, 19, 19]         --\n|    |    └─Conv2d: 3-34                 [-1, 728, 19, 19]         6,552\n|    |    └─Conv2d: 3-35                 [-1, 728, 19, 19]         529,984\n|    |    └─BatchNorm2d: 3-36            [-1, 728, 19, 19]         1,456\n|    |    └─ReLU: 3-37                   [-1, 728, 19, 19]         --\n|    |    └─Conv2d: 3-38                 [-1, 728, 19, 19]         6,552\n|    |    └─Conv2d: 3-39                 [-1, 728, 19, 19]         529,984\n|    |    └─BatchNorm2d: 3-40            [-1, 728, 19, 19]         1,456\n|    |    └─ReLU: 3-41                   [-1, 728, 19, 19]         --\n|    |    └─Conv2d: 3-42                 [-1, 728, 19, 19]         6,552\n|    |    └─Conv2d: 3-43                 [-1, 728, 19, 19]         529,984\n|    |    └─BatchNorm2d: 3-44            [-1, 728, 19, 19]         1,456\n|    └─MiddleFlow: 2-11                  [-1, 728, 19, 19]         --\n|    |    └─ReLU: 3-45                   [-1, 728, 19, 19]         --\n|    |    └─Conv2d: 3-46                 [-1, 728, 19, 19]         6,552\n|    |    └─Conv2d: 3-47                 [-1, 728, 19, 19]         529,984\n|    |    └─BatchNorm2d: 3-48            [-1, 728, 19, 19]         1,456\n|    |    └─ReLU: 3-49                   [-1, 728, 19, 19]         --\n|    |    └─Conv2d: 3-50                 [-1, 728, 19, 19]         6,552\n|    |    └─Conv2d: 3-51                 [-1, 728, 19, 19]         529,984\n|    |    └─BatchNorm2d: 3-52            [-1, 728, 19, 19]         1,456\n|    |    └─ReLU: 3-53                   [-1, 728, 19, 19]         --\n|    |    └─Conv2d: 3-54                 [-1, 728, 19, 19]         6,552\n|    |    └─Conv2d: 3-55                 [-1, 728, 19, 19]         529,984\n|    |    └─BatchNorm2d: 3-56            [-1, 728, 19, 19]         1,456\n|    └─MiddleFlow: 2-12                  [-1, 728, 19, 19]         --\n|    |    └─ReLU: 3-57                   [-1, 728, 19, 19]         --\n|    |    └─Conv2d: 3-58                 [-1, 728, 19, 19]         6,552\n|    |    └─Conv2d: 3-59                 [-1, 728, 19, 19]         529,984\n|    |    └─BatchNorm2d: 3-60            [-1, 728, 19, 19]         1,456\n|    |    └─ReLU: 3-61                   [-1, 728, 19, 19]         --\n|    |    └─Conv2d: 3-62                 [-1, 728, 19, 19]         6,552\n|    |    └─Conv2d: 3-63                 [-1, 728, 19, 19]         529,984\n|    |    └─BatchNorm2d: 3-64            [-1, 728, 19, 19]         1,456\n|    |    └─ReLU: 3-65                   [-1, 728, 19, 19]         --\n|    |    └─Conv2d: 3-66                 [-1, 728, 19, 19]         6,552\n|    |    └─Conv2d: 3-67                 [-1, 728, 19, 19]         529,984\n|    |    └─BatchNorm2d: 3-68            [-1, 728, 19, 19]         1,456\n|    └─MiddleFlow: 2-13                  [-1, 728, 19, 19]         --\n|    |    └─ReLU: 3-69                   [-1, 728, 19, 19]         --\n|    |    └─Conv2d: 3-70                 [-1, 728, 19, 19]         6,552\n|    |    └─Conv2d: 3-71                 [-1, 728, 19, 19]         529,984\n|    |    └─BatchNorm2d: 3-72            [-1, 728, 19, 19]         1,456\n|    |    └─ReLU: 3-73                   [-1, 728, 19, 19]         --\n|    |    └─Conv2d: 3-74                 [-1, 728, 19, 19]         6,552\n|    |    └─Conv2d: 3-75                 [-1, 728, 19, 19]         529,984\n|    |    └─BatchNorm2d: 3-76            [-1, 728, 19, 19]         1,456\n|    |    └─ReLU: 3-77                   [-1, 728, 19, 19]         --\n|    |    └─Conv2d: 3-78                 [-1, 728, 19, 19]         6,552\n|    |    └─Conv2d: 3-79                 [-1, 728, 19, 19]         529,984\n|    |    └─BatchNorm2d: 3-80            [-1, 728, 19, 19]         1,456\n|    └─MiddleFlow: 2-14                  [-1, 728, 19, 19]         --\n|    |    └─ReLU: 3-81                   [-1, 728, 19, 19]         --\n|    |    └─Conv2d: 3-82                 [-1, 728, 19, 19]         6,552\n|    |    └─Conv2d: 3-83                 [-1, 728, 19, 19]         529,984\n|    |    └─BatchNorm2d: 3-84            [-1, 728, 19, 19]         1,456\n|    |    └─ReLU: 3-85                   [-1, 728, 19, 19]         --\n|    |    └─Conv2d: 3-86                 [-1, 728, 19, 19]         6,552\n|    |    └─Conv2d: 3-87                 [-1, 728, 19, 19]         529,984\n|    |    └─BatchNorm2d: 3-88            [-1, 728, 19, 19]         1,456\n|    |    └─ReLU: 3-89                   [-1, 728, 19, 19]         --\n|    |    └─Conv2d: 3-90                 [-1, 728, 19, 19]         6,552\n|    |    └─Conv2d: 3-91                 [-1, 728, 19, 19]         529,984\n|    |    └─BatchNorm2d: 3-92            [-1, 728, 19, 19]         1,456\n|    └─MiddleFlow: 2-15                  [-1, 728, 19, 19]         --\n|    |    └─ReLU: 3-93                   [-1, 728, 19, 19]         --\n|    |    └─Conv2d: 3-94                 [-1, 728, 19, 19]         6,552\n|    |    └─Conv2d: 3-95                 [-1, 728, 19, 19]         529,984\n|    |    └─BatchNorm2d: 3-96            [-1, 728, 19, 19]         1,456\n|    |    └─ReLU: 3-97                   [-1, 728, 19, 19]         --\n|    |    └─Conv2d: 3-98                 [-1, 728, 19, 19]         6,552\n|    |    └─Conv2d: 3-99                 [-1, 728, 19, 19]         529,984\n|    |    └─BatchNorm2d: 3-100           [-1, 728, 19, 19]         1,456\n|    |    └─ReLU: 3-101                  [-1, 728, 19, 19]         --\n|    |    └─Conv2d: 3-102                [-1, 728, 19, 19]         6,552\n|    |    └─Conv2d: 3-103                [-1, 728, 19, 19]         529,984\n|    |    └─BatchNorm2d: 3-104           [-1, 728, 19, 19]         1,456\n|    └─MiddleFlow: 2-16                  [-1, 728, 19, 19]         --\n|    |    └─ReLU: 3-105                  [-1, 728, 19, 19]         --\n|    |    └─Conv2d: 3-106                [-1, 728, 19, 19]         6,552\n|    |    └─Conv2d: 3-107                [-1, 728, 19, 19]         529,984\n|    |    └─BatchNorm2d: 3-108           [-1, 728, 19, 19]         1,456\n|    |    └─ReLU: 3-109                  [-1, 728, 19, 19]         --\n|    |    └─Conv2d: 3-110                [-1, 728, 19, 19]         6,552\n|    |    └─Conv2d: 3-111                [-1, 728, 19, 19]         529,984\n|    |    └─BatchNorm2d: 3-112           [-1, 728, 19, 19]         1,456\n|    |    └─ReLU: 3-113                  [-1, 728, 19, 19]         --\n|    |    └─Conv2d: 3-114                [-1, 728, 19, 19]         6,552\n|    |    └─Conv2d: 3-115                [-1, 728, 19, 19]         529,984\n|    |    └─BatchNorm2d: 3-116           [-1, 728, 19, 19]         1,456\n|    └─MiddleFlow: 2-17                  [-1, 728, 19, 19]         --\n|    |    └─ReLU: 3-117                  [-1, 728, 19, 19]         --\n|    |    └─Conv2d: 3-118                [-1, 728, 19, 19]         6,552\n|    |    └─Conv2d: 3-119                [-1, 728, 19, 19]         529,984\n|    |    └─BatchNorm2d: 3-120           [-1, 728, 19, 19]         1,456\n|    |    └─ReLU: 3-121                  [-1, 728, 19, 19]         --\n|    |    └─Conv2d: 3-122                [-1, 728, 19, 19]         6,552\n|    |    └─Conv2d: 3-123                [-1, 728, 19, 19]         529,984\n|    |    └─BatchNorm2d: 3-124           [-1, 728, 19, 19]         1,456\n|    |    └─ReLU: 3-125                  [-1, 728, 19, 19]         --\n|    |    └─Conv2d: 3-126                [-1, 728, 19, 19]         6,552\n|    |    └─Conv2d: 3-127                [-1, 728, 19, 19]         529,984\n|    |    └─BatchNorm2d: 3-128           [-1, 728, 19, 19]         1,456\n├─ExitFlowFinal: 1-3                     [-1, 2048, 1, 1]          --\n|    └─Conv2d: 2-18                      [-1, 1024, 10, 10]        746,496\n|    └─BatchNorm2d: 2-19                 [-1, 1024, 10, 10]        2,048\n|    └─ReLU: 2-20                        [-1, 728, 19, 19]         --\n|    └─Conv2d: 2-21                      [-1, 728, 19, 19]         6,552\n|    └─Conv2d: 2-22                      [-1, 728, 19, 19]         529,984\n|    └─BatchNorm2d: 2-23                 [-1, 728, 19, 19]         1,456\n|    └─ReLU: 2-24                        [-1, 728, 19, 19]         --\n|    └─Conv2d: 2-25                      [-1, 728, 19, 19]         6,552\n|    └─Conv2d: 2-26                      [-1, 1024, 19, 19]        745,472\n|    └─BatchNorm2d: 2-27                 [-1, 1024, 19, 19]        2,048\n|    └─MaxPool2d: 2-28                   [-1, 1024, 10, 10]        --\n|    └─Conv2d: 2-29                      [-1, 1024, 10, 10]        9,216\n|    └─Conv2d: 2-30                      [-1, 1536, 10, 10]        1,572,864\n|    └─BatchNorm2d: 2-31                 [-1, 1536, 10, 10]        3,072\n|    └─ReLU: 2-32                        [-1, 1536, 10, 10]        --\n|    └─Conv2d: 2-33                      [-1, 1536, 10, 10]        13,824\n|    └─Conv2d: 2-34                      [-1, 2048, 10, 10]        3,145,728\n|    └─BatchNorm2d: 2-35                 [-1, 2048, 10, 10]        4,096\n|    └─ReLU: 2-36                        [-1, 2048, 10, 10]        --\n|    └─AvgPool2d: 2-37                   [-1, 2048, 1, 1]          --\n├─Linear: 1-4                            [-1, 512]                 1,049,088\n├─ReLU: 1-5                              [-1, 512]                 --\n├─Linear: 1-6                            [-1, 275]                 141,075\n├─ReLU: 1-7                              [-1, 275]                 --\n==========================================================================================\nTotal params: 21,999,347\nTrainable params: 21,999,347\nNon-trainable params: 0\nTotal mult-adds (G): 8.39\n==========================================================================================\nInput size (MB): 1.02\nForward/backward pass size (MB): 434.59\nParams size (MB): 83.92\nEstimated Total Size (MB): 519.54\n==========================================================================================\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\n├─EntryFlowFinal: 1-1                    [-1, 728, 19, 19]         --\n|    └─Conv2d: 2-1                       [-1, 32, 149, 149]        896\n|    └─BatchNorm2d: 2-2                  [-1, 32, 149, 149]        64\n|    └─ReLU: 2-3                         [-1, 32, 149, 149]        --\n|    └─Conv2d: 2-4                       [-1, 64, 147, 147]        18,496\n|    └─BatchNorm2d: 2-5                  [-1, 64, 147, 147]        128\n|    └─ReLU: 2-6                         [-1, 64, 147, 147]        --\n|    └─EntryFlowLoop: 2-7                [-1, 128, 74, 74]         --\n|    |    └─Conv2d: 3-1                  [-1, 128, 74, 74]         8,320\n|    |    └─BatchNorm2d: 3-2             [-1, 128, 74, 74]         256\n|    |    └─Conv2d: 3-3                  [-1, 64, 147, 147]        576\n|    |    └─Conv2d: 3-4                  [-1, 128, 147, 147]       8,192\n|    |    └─BatchNorm2d: 3-5             [-1, 128, 147, 147]       256\n|    |    └─ReLU: 3-6                    [-1, 128, 147, 147]       --\n|    |    └─Conv2d: 3-7                  [-1, 128, 147, 147]       1,152\n|    |    └─Conv2d: 3-8                  [-1, 128, 147, 147]       16,384\n|    |    └─BatchNorm2d: 3-9             [-1, 128, 147, 147]       256\n|    |    └─MaxPool2d: 3-10              [-1, 128, 74, 74]         --\n|    └─EntryFlowLoop: 2-8                [-1, 256, 37, 37]         --\n|    |    └─Conv2d: 3-11                 [-1, 256, 37, 37]         33,024\n|    |    └─BatchNorm2d: 3-12            [-1, 256, 37, 37]         512\n|    |    └─ReLU: 3-13                   [-1, 128, 74, 74]         --\n|    |    └─Conv2d: 3-14                 [-1, 128, 74, 74]         1,152\n|    |    └─Conv2d: 3-15                 [-1, 256, 74, 74]         32,768\n|    |    └─BatchNorm2d: 3-16            [-1, 256, 74, 74]         512\n|    |    └─ReLU: 3-17                   [-1, 256, 74, 74]         --\n|    |    └─Conv2d: 3-18                 [-1, 256, 74, 74]         2,304\n|    |    └─Conv2d: 3-19                 [-1, 256, 74, 74]         65,536\n|    |    └─BatchNorm2d: 3-20            [-1, 256, 74, 74]         512\n|    |    └─MaxPool2d: 3-21              [-1, 256, 37, 37]         --\n|    └─EntryFlowLoop: 2-9                [-1, 728, 19, 19]         --\n|    |    └─Conv2d: 3-22                 [-1, 728, 19, 19]         187,096\n|    |    └─BatchNorm2d: 3-23            [-1, 728, 19, 19]         1,456\n|    |    └─ReLU: 3-24                   [-1, 256, 37, 37]         --\n|    |    └─Conv2d: 3-25                 [-1, 256, 37, 37]         2,304\n|    |    └─Conv2d: 3-26                 [-1, 728, 37, 37]         186,368\n|    |    └─BatchNorm2d: 3-27            [-1, 728, 37, 37]         1,456\n|    |    └─ReLU: 3-28                   [-1, 728, 37, 37]         --\n|    |    └─Conv2d: 3-29                 [-1, 728, 37, 37]         6,552\n|    |    └─Conv2d: 3-30                 [-1, 728, 37, 37]         529,984\n|    |    └─BatchNorm2d: 3-31            [-1, 728, 37, 37]         1,456\n|    |    └─MaxPool2d: 3-32              [-1, 728, 19, 19]         --\n├─MiddleFlowFinal: 1-2                   [-1, 728, 19, 19]         --\n|    └─MiddleFlow: 2-10                  [-1, 728, 19, 19]         --\n|    |    └─ReLU: 3-33                   [-1, 728, 19, 19]         --\n|    |    └─Conv2d: 3-34                 [-1, 728, 19, 19]         6,552\n|    |    └─Conv2d: 3-35                 [-1, 728, 19, 19]         529,984\n|    |    └─BatchNorm2d: 3-36            [-1, 728, 19, 19]         1,456\n|    |    └─ReLU: 3-37                   [-1, 728, 19, 19]         --\n|    |    └─Conv2d: 3-38                 [-1, 728, 19, 19]         6,552\n|    |    └─Conv2d: 3-39                 [-1, 728, 19, 19]         529,984\n|    |    └─BatchNorm2d: 3-40            [-1, 728, 19, 19]         1,456\n|    |    └─ReLU: 3-41                   [-1, 728, 19, 19]         --\n|    |    └─Conv2d: 3-42                 [-1, 728, 19, 19]         6,552\n|    |    └─Conv2d: 3-43                 [-1, 728, 19, 19]         529,984\n|    |    └─BatchNorm2d: 3-44            [-1, 728, 19, 19]         1,456\n|    └─MiddleFlow: 2-11                  [-1, 728, 19, 19]         --\n|    |    └─ReLU: 3-45                   [-1, 728, 19, 19]         --\n|    |    └─Conv2d: 3-46                 [-1, 728, 19, 19]         6,552\n|    |    └─Conv2d: 3-47                 [-1, 728, 19, 19]         529,984\n|    |    └─BatchNorm2d: 3-48            [-1, 728, 19, 19]         1,456\n|    |    └─ReLU: 3-49                   [-1, 728, 19, 19]         --\n|    |    └─Conv2d: 3-50                 [-1, 728, 19, 19]         6,552\n|    |    └─Conv2d: 3-51                 [-1, 728, 19, 19]         529,984\n|    |    └─BatchNorm2d: 3-52            [-1, 728, 19, 19]         1,456\n|    |    └─ReLU: 3-53                   [-1, 728, 19, 19]         --\n|    |    └─Conv2d: 3-54                 [-1, 728, 19, 19]         6,552\n|    |    └─Conv2d: 3-55                 [-1, 728, 19, 19]         529,984\n|    |    └─BatchNorm2d: 3-56            [-1, 728, 19, 19]         1,456\n|    └─MiddleFlow: 2-12                  [-1, 728, 19, 19]         --\n|    |    └─ReLU: 3-57                   [-1, 728, 19, 19]         --\n|    |    └─Conv2d: 3-58                 [-1, 728, 19, 19]         6,552\n|    |    └─Conv2d: 3-59                 [-1, 728, 19, 19]         529,984\n|    |    └─BatchNorm2d: 3-60            [-1, 728, 19, 19]         1,456\n|    |    └─ReLU: 3-61                   [-1, 728, 19, 19]         --\n|    |    └─Conv2d: 3-62                 [-1, 728, 19, 19]         6,552\n|    |    └─Conv2d: 3-63                 [-1, 728, 19, 19]         529,984\n|    |    └─BatchNorm2d: 3-64            [-1, 728, 19, 19]         1,456\n|    |    └─ReLU: 3-65                   [-1, 728, 19, 19]         --\n|    |    └─Conv2d: 3-66                 [-1, 728, 19, 19]         6,552\n|    |    └─Conv2d: 3-67                 [-1, 728, 19, 19]         529,984\n|    |    └─BatchNorm2d: 3-68            [-1, 728, 19, 19]         1,456\n|    └─MiddleFlow: 2-13                  [-1, 728, 19, 19]         --\n|    |    └─ReLU: 3-69                   [-1, 728, 19, 19]         --\n|    |    └─Conv2d: 3-70                 [-1, 728, 19, 19]         6,552\n|    |    └─Conv2d: 3-71                 [-1, 728, 19, 19]         529,984\n|    |    └─BatchNorm2d: 3-72            [-1, 728, 19, 19]         1,456\n|    |    └─ReLU: 3-73                   [-1, 728, 19, 19]         --\n|    |    └─Conv2d: 3-74                 [-1, 728, 19, 19]         6,552\n|    |    └─Conv2d: 3-75                 [-1, 728, 19, 19]         529,984\n|    |    └─BatchNorm2d: 3-76            [-1, 728, 19, 19]         1,456\n|    |    └─ReLU: 3-77                   [-1, 728, 19, 19]         --\n|    |    └─Conv2d: 3-78                 [-1, 728, 19, 19]         6,552\n|    |    └─Conv2d: 3-79                 [-1, 728, 19, 19]         529,984\n|    |    └─BatchNorm2d: 3-80            [-1, 728, 19, 19]         1,456\n|    └─MiddleFlow: 2-14                  [-1, 728, 19, 19]         --\n|    |    └─ReLU: 3-81                   [-1, 728, 19, 19]         --\n|    |    └─Conv2d: 3-82                 [-1, 728, 19, 19]         6,552\n|    |    └─Conv2d: 3-83                 [-1, 728, 19, 19]         529,984\n|    |    └─BatchNorm2d: 3-84            [-1, 728, 19, 19]         1,456\n|    |    └─ReLU: 3-85                   [-1, 728, 19, 19]         --\n|    |    └─Conv2d: 3-86                 [-1, 728, 19, 19]         6,552\n|    |    └─Conv2d: 3-87                 [-1, 728, 19, 19]         529,984\n|    |    └─BatchNorm2d: 3-88            [-1, 728, 19, 19]         1,456\n|    |    └─ReLU: 3-89                   [-1, 728, 19, 19]         --\n|    |    └─Conv2d: 3-90                 [-1, 728, 19, 19]         6,552\n|    |    └─Conv2d: 3-91                 [-1, 728, 19, 19]         529,984\n|    |    └─BatchNorm2d: 3-92            [-1, 728, 19, 19]         1,456\n|    └─MiddleFlow: 2-15                  [-1, 728, 19, 19]         --\n|    |    └─ReLU: 3-93                   [-1, 728, 19, 19]         --\n|    |    └─Conv2d: 3-94                 [-1, 728, 19, 19]         6,552\n|    |    └─Conv2d: 3-95                 [-1, 728, 19, 19]         529,984\n|    |    └─BatchNorm2d: 3-96            [-1, 728, 19, 19]         1,456\n|    |    └─ReLU: 3-97                   [-1, 728, 19, 19]         --\n|    |    └─Conv2d: 3-98                 [-1, 728, 19, 19]         6,552\n|    |    └─Conv2d: 3-99                 [-1, 728, 19, 19]         529,984\n|    |    └─BatchNorm2d: 3-100           [-1, 728, 19, 19]         1,456\n|    |    └─ReLU: 3-101                  [-1, 728, 19, 19]         --\n|    |    └─Conv2d: 3-102                [-1, 728, 19, 19]         6,552\n|    |    └─Conv2d: 3-103                [-1, 728, 19, 19]         529,984\n|    |    └─BatchNorm2d: 3-104           [-1, 728, 19, 19]         1,456\n|    └─MiddleFlow: 2-16                  [-1, 728, 19, 19]         --\n|    |    └─ReLU: 3-105                  [-1, 728, 19, 19]         --\n|    |    └─Conv2d: 3-106                [-1, 728, 19, 19]         6,552\n|    |    └─Conv2d: 3-107                [-1, 728, 19, 19]         529,984\n|    |    └─BatchNorm2d: 3-108           [-1, 728, 19, 19]         1,456\n|    |    └─ReLU: 3-109                  [-1, 728, 19, 19]         --\n|    |    └─Conv2d: 3-110                [-1, 728, 19, 19]         6,552\n|    |    └─Conv2d: 3-111                [-1, 728, 19, 19]         529,984\n|    |    └─BatchNorm2d: 3-112           [-1, 728, 19, 19]         1,456\n|    |    └─ReLU: 3-113                  [-1, 728, 19, 19]         --\n|    |    └─Conv2d: 3-114                [-1, 728, 19, 19]         6,552\n|    |    └─Conv2d: 3-115                [-1, 728, 19, 19]         529,984\n|    |    └─BatchNorm2d: 3-116           [-1, 728, 19, 19]         1,456\n|    └─MiddleFlow: 2-17                  [-1, 728, 19, 19]         --\n|    |    └─ReLU: 3-117                  [-1, 728, 19, 19]         --\n|    |    └─Conv2d: 3-118                [-1, 728, 19, 19]         6,552\n|    |    └─Conv2d: 3-119                [-1, 728, 19, 19]         529,984\n|    |    └─BatchNorm2d: 3-120           [-1, 728, 19, 19]         1,456\n|    |    └─ReLU: 3-121                  [-1, 728, 19, 19]         --\n|    |    └─Conv2d: 3-122                [-1, 728, 19, 19]         6,552\n|    |    └─Conv2d: 3-123                [-1, 728, 19, 19]         529,984\n|    |    └─BatchNorm2d: 3-124           [-1, 728, 19, 19]         1,456\n|    |    └─ReLU: 3-125                  [-1, 728, 19, 19]         --\n|    |    └─Conv2d: 3-126                [-1, 728, 19, 19]         6,552\n|    |    └─Conv2d: 3-127                [-1, 728, 19, 19]         529,984\n|    |    └─BatchNorm2d: 3-128           [-1, 728, 19, 19]         1,456\n├─ExitFlowFinal: 1-3                     [-1, 2048, 1, 1]          --\n|    └─Conv2d: 2-18                      [-1, 1024, 10, 10]        746,496\n|    └─BatchNorm2d: 2-19                 [-1, 1024, 10, 10]        2,048\n|    └─ReLU: 2-20                        [-1, 728, 19, 19]         --\n|    └─Conv2d: 2-21                      [-1, 728, 19, 19]         6,552\n|    └─Conv2d: 2-22                      [-1, 728, 19, 19]         529,984\n|    └─BatchNorm2d: 2-23                 [-1, 728, 19, 19]         1,456\n|    └─ReLU: 2-24                        [-1, 728, 19, 19]         --\n|    └─Conv2d: 2-25                      [-1, 728, 19, 19]         6,552\n|    └─Conv2d: 2-26                      [-1, 1024, 19, 19]        745,472\n|    └─BatchNorm2d: 2-27                 [-1, 1024, 19, 19]        2,048\n|    └─MaxPool2d: 2-28                   [-1, 1024, 10, 10]        --\n|    └─Conv2d: 2-29                      [-1, 1024, 10, 10]        9,216\n|    └─Conv2d: 2-30                      [-1, 1536, 10, 10]        1,572,864\n|    └─BatchNorm2d: 2-31                 [-1, 1536, 10, 10]        3,072\n|    └─ReLU: 2-32                        [-1, 1536, 10, 10]        --\n|    └─Conv2d: 2-33                      [-1, 1536, 10, 10]        13,824\n|    └─Conv2d: 2-34                      [-1, 2048, 10, 10]        3,145,728\n|    └─BatchNorm2d: 2-35                 [-1, 2048, 10, 10]        4,096\n|    └─ReLU: 2-36                        [-1, 2048, 10, 10]        --\n|    └─AvgPool2d: 2-37                   [-1, 2048, 1, 1]          --\n├─Linear: 1-4                            [-1, 512]                 1,049,088\n├─ReLU: 1-5                              [-1, 512]                 --\n├─Linear: 1-6                            [-1, 275]                 141,075\n├─ReLU: 1-7                              [-1, 275]                 --\n==========================================================================================\nTotal params: 21,999,347\nTrainable params: 21,999,347\nNon-trainable params: 0\nTotal mult-adds (G): 8.39\n==========================================================================================\nInput size (MB): 1.02\nForward/backward pass size (MB): 434.59\nParams size (MB): 83.92\nEstimated Total Size (MB): 519.54\n=========================================================================================="},"metadata":{}}]},{"cell_type":"code","source":"import torch.optim as optim\n\n# specify loss function\ncriterion = nn.CrossEntropyLoss()\n\n# specify optimizer\noptimizer = optim.SGD(model.parameters(),lr=0.02, momentum=0.9)\n# optimizer = optim.Adam(model.parameters(), lr = 0.00005)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T12:09:34.709640Z","iopub.execute_input":"2021-08-02T12:09:34.710022Z","iopub.status.idle":"2021-08-02T12:09:34.717865Z","shell.execute_reply.started":"2021-08-02T12:09:34.709988Z","shell.execute_reply":"2021-08-02T12:09:34.716487Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# Trying different lr and Optimizers to suits the data\n\n### SGD, lr=0.0005  \n100 train loss =  4.293675837516784  \n200 train loss =  3.5160562169551848  \n300 train loss =  3.1869335826237997  \n400 train loss =  2.995716138780117  \n500 train loss =  2.8791215178966523  \n600 train loss =  2.778849496046702  \n\n### SGD, lr=0.001  \n100 train loss =  3.5865376210212707  \n200 train loss =  3.1011905866861342  \n300 train loss =  2.853240623474121  \n400 train loss =  2.722959086894989  \n500 train loss =  2.635439955234528  \n600 train loss =  2.568245601654053  \n\n### SGD, lr=0.005  \n100 train loss =  3.3242822325229646  \n200 train loss =  2.8887323570251464  \n300 train loss =  2.7026949417591095  \n400 train loss =  2.5906972613930703  \n500 train loss =  2.4937503309249878  \n600 train loss =  2.4266555760304134  \n\n### SGD, lr=0.007  \n100 train loss =  3.410749969482422  \n200 train loss =  2.9440751534700396  \n300 train loss =  2.6484226047992707  \n400 train loss =  2.4255268818140028  \n500 train loss =  2.2726909840106964  \n\n### SGD, lr=0.01  \n\n100 train loss =  3.286306972503662  \n200 train loss =  2.927250148653984  \n300 train loss =  2.7289543612798055  \n400 train loss =  2.6260555094480513  \n500 train loss =  2.5271109757423402  \n600 train loss =  2.3860551651318866  \n\n### SGD, lr=0.02  \n\n100 train loss =  2.632558946609497  \n200 train loss =  2.322135624289513  \n300 train loss =  2.1878742357095082  \n400 train loss =  2.100518697798252  \n500 train loss =  2.0330836935043335  \n600 train loss =  1.9819465831915537  \n\n\n\n### SGD, lr=0.03  \n100 train loss =  3.141713446378708  \n200 train loss =  2.8451237058639527  \n300 train loss =  2.7730438776810966  \n400 train loss =  2.695722301900387  \n500 train loss =  2.6434776804447173  \n600 train loss =  2.5930514949560166  \n\n## Optimizer change to Adam  \n\n### Adam, lr=0.1\n\n100 train loss =  21.78967511177063  \n200 train loss =  13.34359126329422  \n\n### Adam, lr=0.05  \n100 train loss =  10.229436330795288  \n200 train loss =  6.703847949504852  \n\n### Adam, lr=0.01  \n100 train loss =  4.773248999118805  \n200 train loss =  4.5610452401638035  \n300 train loss =  4.43212244908015  \n400 train loss =  4.393921576142311  \n500 train loss =  4.357113010406494  \n600 train loss =  4.320134338537852  \n\n### Adam, lr=0.005  \n100 train loss =  4.843475396633148  \n200 train loss =  4.747493587732315  \n300 train loss =  4.689231255849203  \n400 train loss =  4.645357070565224  \n\n### Adam, lr=0.001  \n100 train loss =  3.5790255165100096  \n200 train loss =  3.4403728437423706  \n300 train loss =  3.3438539365927378  \n400 train loss =  3.2561190494894983  \n500 train loss =  3.219608674287796  \n\n### Adam, lr=0.0005  \n100 train loss =  3.8323942432403566  \n200 train loss =  3.714814779758453  \n300 train loss =  3.605844489336014  \n400 train loss =  3.529643462896347  \n500 train loss =  3.4812713096141816\n\n### Adam, lr=0.0001  \n100 train loss =  3.6713942432403566  \n200 train loss =  3.414814779758453  \n300 train loss =  3.305844489336014  \n400 train loss =  3.229643462896347  \n500 train loss =  3.1812713096141816  \n\n### Adam, lr=0.00005  \n100 train loss =  3.7643074476718903  \n200 train loss =  3.2872815561294555  \n300 train loss =  3.0677139552434287  \n400 train loss =  2.9719791358709333  \n500 train loss =  2.8868279342651366  \n\n\n\n","metadata":{}},{"cell_type":"code","source":"n_epochs = 25\nvalid_loss_min = np.Inf # track change in validation loss\nbatch_number=0\nfor epoch in range(1, n_epochs+1):\n\n    # keep track of training and validation loss\n    train_loss = 0.0\n    valid_loss = 0.0\n    \n    ###################\n    # train the model #\n    ###################\n    model.train()\n    \n    for data, target in train_loader:\n        batch_number+=1\n        \n        # move tensors to GPU if CUDA is available\n        if train_on_gpu:\n            data, target = data.cuda(), target.cuda()\n        # clear the gradients of all optimized variables\n        optimizer.zero_grad()\n        # forward pass: compute predicted outputs by passing inputs to the model\n        output = model(data)\n        # calculate the batch loss\n\n        #output =output.reshape(20,-1)\n        #print(output.shape)\n        loss = criterion(output, target)\n\n        # backward pass: compute gradient of the loss with respect to model parameters\n        loss.backward()\n        # perform a single optimization step (parameter update)\n        optimizer.step()\n        # update training loss\n        train_loss += loss.item()*data.size(0)\n        if batch_number%400==0:\n            print(batch_number)\n            torch.save(model.state_dict(), 'model_cifar_1.pt')\n\n    ######################    \n    # validate the model #\n    ######################\n    model.eval()\n    for data, target in valid_loader:\n        # move tensors to GPU if CUDA is available\n        if train_on_gpu:\n            data, target = data.cuda(), target.cuda()\n        # forward pass: compute predicted outputs by passing inputs to the model\n        output = model(data)\n        # calculate the batch loss\n        loss = criterion(output, target)\n        # update average validation loss \n        valid_loss += loss.item()*data.size(0)\n    \n    # calculate average losses\n    train_loss = train_loss/len(train_loader.dataset)\n    valid_loss = valid_loss/len(valid_loader.dataset)\n        \n    # print training/validation statistics \n    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n        epoch, train_loss, valid_loss))\n    \n    # save model if validation loss has decreased\n    if valid_loss <= valid_loss_min:\n        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n        valid_loss_min,\n        valid_loss))\n        torch.save(model.state_dict(), 'model_cifar.pt')\n        valid_loss_min = valid_loss","metadata":{"execution":{"iopub.status.busy":"2021-08-02T09:31:51.331554Z","iopub.execute_input":"2021-08-02T09:31:51.331948Z","iopub.status.idle":"2021-08-02T11:49:42.507836Z","shell.execute_reply.started":"2021-08-02T09:31:51.331915Z","shell.execute_reply":"2021-08-02T11:49:42.505871Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"400\n800\n1200\n1600\nEpoch: 1 \tTraining Loss: 1.370068 \tValidation Loss: 0.251383\nValidation loss decreased (inf --> 0.251383).  Saving model ...\n2000\n2400\n2800\n3200\nEpoch: 2 \tTraining Loss: 0.842680 \tValidation Loss: 0.179407\nValidation loss decreased (0.251383 --> 0.179407).  Saving model ...\n3600\n4000\n4400\n4800\nEpoch: 3 \tTraining Loss: 0.614722 \tValidation Loss: 0.154220\nValidation loss decreased (0.179407 --> 0.154220).  Saving model ...\n5200\n5600\n6000\n6400\nEpoch: 4 \tTraining Loss: 0.468443 \tValidation Loss: 0.117426\nValidation loss decreased (0.154220 --> 0.117426).  Saving model ...\n6800\n7200\n7600\n8000\nEpoch: 5 \tTraining Loss: 0.362242 \tValidation Loss: 0.099673\nValidation loss decreased (0.117426 --> 0.099673).  Saving model ...\n8400\n8800\n9200\n9600\n10000\nEpoch: 6 \tTraining Loss: 0.293766 \tValidation Loss: 0.099219\nValidation loss decreased (0.099673 --> 0.099219).  Saving model ...\n10400\n10800\n11200\n11600\nEpoch: 7 \tTraining Loss: 0.228736 \tValidation Loss: 0.093741\nValidation loss decreased (0.099219 --> 0.093741).  Saving model ...\n12000\n12400\n12800\n13200\nEpoch: 8 \tTraining Loss: 0.183901 \tValidation Loss: 0.099725\n13600\n14000\n14400\n14800\nEpoch: 9 \tTraining Loss: 0.150353 \tValidation Loss: 0.114262\n15200\n15600\n16000\n16400\nEpoch: 10 \tTraining Loss: 0.118938 \tValidation Loss: 0.095533\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-648274f09531>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m# perform a single optimization step (parameter update)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;31m# update training loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/optim/sgd.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    104\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'momentum_buffer'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m                         \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdampening\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mnesterov\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m                         \u001b[0md_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_p\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"torch.save(model.state_dict(), 'model_cifar_1.pt')","metadata":{"execution":{"iopub.status.busy":"2021-06-25T16:35:08.36943Z","iopub.execute_input":"2021-06-25T16:35:08.369752Z","iopub.status.idle":"2021-06-25T16:35:08.438959Z","shell.execute_reply.started":"2021-06-25T16:35:08.369724Z","shell.execute_reply":"2021-06-25T16:35:08.43812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_state_dict(torch.load('model_cifar.pt'))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model1 = Xception_implementation()\nmodel2 = Xception_implementation()\n\n\n# move tensors to GPU if CUDA is available\nif train_on_gpu:\n    model1.cuda()\n    model2.cuda()\n\nmodel1.load_state_dict(torch.load('../input/saved-models-cifar10/model_cifar (7).pt'))\nmodel2.load_state_dict(torch.load('../input/saved-models-cifar10/model_cifar_1.pt'))","metadata":{"execution":{"iopub.status.busy":"2021-08-02T12:10:04.893347Z","iopub.execute_input":"2021-08-02T12:10:04.893656Z","iopub.status.idle":"2021-08-02T12:10:09.104242Z","shell.execute_reply.started":"2021-08-02T12:10:04.893629Z","shell.execute_reply":"2021-08-02T12:10:09.103438Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"cell_type":"code","source":"model=model2\ntest_loss = 0.0\nclass_correct = list(0. for i in range(10))\nclass_total = list(0. for i in range(10))\n\nmodel.eval()\n# iterate over test data\nfor data, target in test_loader:\n    # move tensors to GPU if CUDA is available\n    if train_on_gpu:\n        data, target = data.cuda(), target.cuda()\n    # forward pass: compute predicted outputs by passing inputs to the model\n    output = model(data)\n    # calculate the batch loss\n    loss = criterion(output, target)\n    # update test loss \n    test_loss += loss.item()*data.size(0)\n    # convert output probabilities to predicted class\n    _, pred = torch.max(output, 1)    \n    # compare predictions to true label\n    correct_tensor = pred.eq(target.data.view_as(pred))\n    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n    # calculate test accuracy for each object class\n    batch_size=data.size(0)\n    for i in range(batch_size):\n        label = target.data[i]\n        class_correct[label] += correct[i].item()\n        class_total[label] += 1\n\n# average test loss\ntest_loss = test_loss/len(test_loader.dataset)\nprint('Test Loss: {:.6f}\\n'.format(test_loss))\n\nfor i in range(10):\n    if class_total[i] > 0:\n        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n            classes[i], 100 * class_correct[i] / class_total[i],\n            np.sum(class_correct[i]), np.sum(class_total[i])))\n    else:\n        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n\nprint('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n    100. * np.sum(class_correct) / np.sum(class_total),\n\n    np.sum(class_correct), np.sum(class_total)))","metadata":{"execution":{"iopub.status.busy":"2021-08-02T12:14:27.162653Z","iopub.execute_input":"2021-08-02T12:14:27.163027Z","iopub.status.idle":"2021-08-02T12:15:33.421885Z","shell.execute_reply.started":"2021-08-02T12:14:27.162994Z","shell.execute_reply":"2021-08-02T12:15:33.420999Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Test Loss: 0.537241\n\nTest Accuracy of airplane: 83% (836/1000)\nTest Accuracy of automobile: 92% (924/1000)\nTest Accuracy of  bird: 78% (788/1000)\nTest Accuracy of   cat: 53% (538/1000)\nTest Accuracy of  deer: 82% (821/1000)\nTest Accuracy of   dog: 88% (881/1000)\nTest Accuracy of  frog: 89% (894/1000)\nTest Accuracy of horse: 92% (922/1000)\nTest Accuracy of  ship: 93% (939/1000)\nTest Accuracy of truck: 95% (953/1000)\n\nTest Accuracy (Overall): 84% (8496/10000)\n","output_type":"stream"}]},{"cell_type":"code","source":"model=model1\ntest_loss = 0.0\nclass_correct = list(0. for i in range(10))\nclass_total = list(0. for i in range(10))\n\nmodel.eval()\n# iterate over test data\nfor data, target in test_loader:\n    # move tensors to GPU if CUDA is available\n    if train_on_gpu:\n        data, target = data.cuda(), target.cuda()\n    # forward pass: compute predicted outputs by passing inputs to the model\n    output = model(data)\n    # calculate the batch loss\n    loss = criterion(output, target)\n    # update test loss \n    test_loss += loss.item()*data.size(0)\n    # convert output probabilities to predicted class\n    _, pred = torch.max(output, 1)    \n    # compare predictions to true label\n    correct_tensor = pred.eq(target.data.view_as(pred))\n    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n    # calculate test accuracy for each object class\n    batch_size=data.size(0)\n    for i in range(batch_size):\n        \n        label = target.data[i]\n        class_correct[label] += correct[i].item()\n        class_total[label] += 1\n\n# average test loss\ntest_loss = test_loss/len(test_loader.dataset)\nprint('Test Loss: {:.6f}\\n'.format(test_loss))\n\nfor i in range(10):\n    if class_total[i] > 0:\n        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n            classes[i], 100 * class_correct[i] / class_total[i],\n            np.sum(class_correct[i]), np.sum(class_total[i])))\n    else:\n        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n\nprint('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n    100. * np.sum(class_correct) / np.sum(class_total),\n    np.sum(class_correct), np.sum(class_total)))","metadata":{"execution":{"iopub.status.busy":"2021-08-02T12:15:42.330285Z","iopub.execute_input":"2021-08-02T12:15:42.330640Z","iopub.status.idle":"2021-08-02T12:16:48.829070Z","shell.execute_reply.started":"2021-08-02T12:15:42.330610Z","shell.execute_reply":"2021-08-02T12:16:48.828227Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Test Loss: 0.471307\n\nTest Accuracy of airplane: 84% (848/1000)\nTest Accuracy of automobile: 94% (941/1000)\nTest Accuracy of  bird: 68% (687/1000)\nTest Accuracy of   cat: 80% (800/1000)\nTest Accuracy of  deer: 82% (822/1000)\nTest Accuracy of   dog: 79% (790/1000)\nTest Accuracy of  frog: 93% (939/1000)\nTest Accuracy of horse: 84% (848/1000)\nTest Accuracy of  ship: 95% (955/1000)\nTest Accuracy of truck: 90% (905/1000)\n\nTest Accuracy (Overall): 85% (8535/10000)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### We gat a accuracy of 85 % !!","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}}]}